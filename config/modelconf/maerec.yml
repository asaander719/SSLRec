optimizer:
  name: adam
  lr: 1.e-3
  weight_decay: 0

train:
  epoch: 30
  batch_size: 512
  test_step: 1 # evaluate per {test_step} epochs
  reproducible: true
  seed: 2023
  save_model: true
  trainer: maerec_trainer
  log_loss: false
  pretrain_path: "/home/asaliao/SSLRec/checkpoint/maerec/maerec-reddit-1710592140.pth"

test:
  metrics: [recall, ndcg, mrr] # choose in {ndcg, recall, precision, mrr}
  k: [5, 10, 20] # top-k
  batch_size: 512 # How many users per batch during validation

data:
  type: sequential # choose in {general_cf, multi_behavior, sequential, social}
  name: ml-20m
  seq_aug: true

model:
  name: maerec # case-insensitive
  con_batch: 2048
  max_seq_len: 50
  num_reco_neg: 40
  reg: 1.e-8
  ssl_reg: 1.e-3
  embedding_size: 64
  mask_depth: 3
  path_prob: 0.5
  num_attention_heads: 4
  num_gcn_layers: 2
  num_trm_layers: 2
  num_mask_cand: 50
  mask_steps: 100
  eps: 0.2
  attention_probs_dropout_prob: 0.3
  hidden_dropout_prob: 0.3

tune:
  enable: false # Whether to enable grid search to search for optimal hyperparameters
